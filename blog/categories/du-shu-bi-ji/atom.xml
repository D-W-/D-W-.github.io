<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 读书笔记 | D W]]></title>
  <link href="http://d-w-.github.io/blog/categories/du-shu-bi-ji/atom.xml" rel="self"/>
  <link href="http://d-w-.github.io/"/>
  <updated>2016-04-16T22:02:27+08:00</updated>
  <id>http://d-w-.github.io/</id>
  <author>
    <name><![CDATA[Harry]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Reading Computer Systems(A Programmer’s Perspective):2]]></title>
    <link href="http://d-w-.github.io/blog/2015/08/27/reading-computer-systems-a-programmers-perspective-2/"/>
    <updated>2015-08-27T13:07:02+08:00</updated>
    <id>http://d-w-.github.io/blog/2015/08/27/reading-computer-systems-a-programmers-perspective-2</id>
    <content type="html"><![CDATA[<h2>第五章 优化程序性能</h2>

<p>这一章主要讲的是编译器对代码的一些优化策略,包括在代码效率和代码在一些极端状况下的准确性的权衡.以及用具体的汇编代码及在机器中的实现来说明一些代码习惯的对程序效率的影响,最后介绍了一种unix环境下的程序剖析(profiling)工具GPROF.</p>

<p>优化程序的效率时,除了优化整个算法的时间复杂度,其中编译器对代码的编译也起到了至关重要的作用,而编译器除了要将代码变得更快,还需要考虑程序的正确性,开头的例子给出了一个对源代码非常明显的优化,但是编译器却不敢执行这个优化,主要原因就是他不能保证这个优化过的结果和没优化的结果是一样的,事实上,在极端情况下,优化后的代码可能会产生和原来的代码不同的结果.</p>

<p>所以,编译器的一些优化级别,需要保证对程序只使用<strong>安全</strong>的优化,也就是保证优化后的代码和之前的代码完全相同,这种保证就会使得一些明显的优化无法执行(因为无法保证极端情况下的正确性).</p>

<p>接下来以一个程序(P330)为示例,讲了几种写代码时的优化策略</p>

<h3>消除循环的低效率</h3>

<p>这个说的是可能编程中经常会遇到的问题,循环
<code>for(int i = 0;i&lt;vec_length(v),++i)</code>
如果这么写的话,每次循环结束都会调用 <code>vec_length()</code> 这个函数来确定是否到达循环结束,对于长度不变的数据结构的遍历,每次循环结束调用的这个函数的开销是不必要的,应将其避免</p>

<h3>减少过程调用</h3>

<p>这个部分说的是尽量不要在循环中循环调用一些函数,在循环外拿到需要循环遍历的数据结构,然后再循环中直接去调用数据结构.</p>

<p>书中也提到了这种做法不太符合程序模块化的要求,只有在追求效率的代码中会用到,这种情况也应该写几行注释注明.</p>

<h3>消除不必要的存储器引用</h3>

<p>讲的是,这么写</p>

<pre><code>for(int i = 0;i&lt;length;++i)
    acc = acc OP data[i];
</code></pre>

<p>和这么写</p>

<pre><code>for(int i = 0;i&lt;length;++i)
    *dest = *dest OP data[i];
</code></pre>

<p>前者更好,因为,前者在汇编中实现可以用寄存器存储 acc ,而后者是个指针,汇编中只能用存储器实现,每次去地址再取指会浪费大量时间.</p>

<p>优化程序的两个限制:</p>

<ol>
<li>延迟界限: 从开始到结束完全完成一条指令所需要的时间决定,达到这个界限的原因是下一条指令需要上一条指令执行完毕才能执行,指令间有严格的操作顺序.</li>
<li>吞吐量界限: 指令之间可以<strong>完全流水线化(fully pipelined)</strong>,这样使得硬件的功能达到了最大的利用率,在这种情况下优化只能优化处理器功能单元的<strong>原始计算能力了</strong>.</li>
</ol>


<p>一些编译器可能做的优化</p>

<h3>循环展开</h3>

<p>就是循环每次原来读一个数,优化后每次读 k 个数,这样循环的次数就变成了 [n/k] 次,这样优化结果性能的提升得益于 <strong>减少了循环的开销工作</strong> ,比如原来累加器 iter 原来要累加 n 次,现在只要累加 [n/k] 次了, 降低了开销操作的数量.</p>

<h3>提高并行性</h3>

<p>这个比较容易理解,比如一个累加的程序,原来只有一个累加器,每次加一个数,改成并行的可以有 k 个累加器, k 个累加器同时工作肯定要比原来效率高</p>

<p>不过这里硬件会成为限制条件,后面就提到了<strong>寄存器溢出</strong>这种情况,就是累加器多得在寄存器里面存不下了,只能到栈里面存,这样又增加了存储器开销,反而会使效率下降.</p>

<h3>重新结合变换</h3>

<p>就是利用有结合律的变换,运用一下结合律,比如把下面这个</p>

<pre><code>acc = acc OP data[i] OP data[i+1]
</code></pre>

<p>变成下面这个</p>

<pre><code>acc = add OP (data[i] OP data[i+1])
</code></pre>

<p>代码层面没有改进,但是从汇编层面分析,原来每次循环在 acc 上的运算 由原来的两次变成了一次,这样就缩短了关键路径,从而提高了效率.</p>

<hr />

<p>上一章可以看到分支预测会对程序效率有很大影响,因为是一个完全投机的预测,预测错了下面所有取到的指令都应该放弃,这会造成比较大的损失.但是这也是不可避免的,文中提到了
1. 不要过分关心可预测的分支,我们预测分支往往会执行是因为,再循环中,这样的预测策略只有最后一次会失败,所以几率还是比较大的
2. 在程序猿的角度,将<strong>分支跳转指令</strong>改为<strong>条件传送指令( <code>val = exp?a:b;</code> )</strong>往往能取得比较好的效果,因为条件传送指令不会有错误的开销: <strong>在流水线中,下一条指令译码钱,上一条指令已经完成了执行操作,因此下一条如果是条件传送指令的话,刚好可以通过转发机制得到状态码.</strong></p>

<h2>加载和存储</h2>

<p>读和写都制约程序的运行效率 如下:</p>

<ol>
<li>加载相关, 循环两次之间的读有相关性,下一次的读需要上一次读出来的结果,所以下一条读的指令必须等上一次循环完全结束</li>
<li>读写相关(write/read dependency), 一个存储器读的结果依赖于一个最近的存储器写.这个是经常会遇到的问题.</li>
</ol>


<p>读写相关的解决方案 (<strong>P366</strong>):</p>

<p>在存储单元中有个<strong>存储缓冲区</strong>,包含将会写到存储单元的,但是还没完成的操作(地址,值).
每次读的时候 (<strong>load 指令</strong>)会先检查一下存储缓冲区,如果发现读的地址在存储缓冲区里面(说明呆会会被写进新值),就直接在存储缓冲区里面拿新值了.</p>

<p><em>&hellip;其实上面的操作就是转发</em></p>

<h2>最后 程序剖析(profiling)</h2>

<p>这里介绍了一种分析程序效率的工具,GPROF</p>

<ol>
<li>在编译和链接过程中加上剖析的指令
 <code>gcc -o1 -pg prog.c prog</code></li>
<li>执行程序,会生成一个多余的 gmon.out 的文件
 <code>./prog arguments...</code></li>
<li>使用GPROF来解析这个out文件(必须有out文件才能解析)
 <code>gprof prog</code></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Reading Computer Systems(A Programmer's Perspective):1]]></title>
    <link href="http://d-w-.github.io/blog/2015/08/14/reading-computer-systems-a-programmers-perspective-1/"/>
    <updated>2015-08-14T15:37:43+08:00</updated>
    <id>http://d-w-.github.io/blog/2015/08/14/reading-computer-systems-a-programmers-perspective-1</id>
    <content type="html"><![CDATA[<p>深入理解计算机系统这本书大二的时候就买了,因为有很多学长推荐,而且很多计算机名校也用它当&lt;计算机组成原理>的教材.但是由于各种原因一直拖着没读,大三利用寒假读了一下,感觉受益匪浅,但是没有读完,大三下学期断断续续不仅没有继续读,还把前面读了的忘了个差不多,现在准备利用暑假读完,并记一下笔记,以防忘记.</p>

<hr />

<h2>第四章 处理器体系结构</h2>

<p>这一章主要是将前面几章的理论用于实践,通过一个相对简单的&#8221;Y86&#8221;指令集,介绍了机器代码,汇编代码之间的关系,指令流水等概念.</p>

<p>Y86指令比较简单,只实现了一些基本的指令,指令和数长无关,默认立即数都是4个字节,指令是变长的&hellip;</p>

<ul>
<li>立即数用小端(little-endian)编码,比如 0x12345 变成4字节应该是 0x00 01 23 45 但是存储到内存里面就是 0x 45 23 01 00</li>
<li>数的运算指令会设置条件码 ZF SF 和 OF (零 符号 和 溢出)</li>
<li>程序状态码 Stat 代表了程序运行状态(AOK, HLT, ADR, INS),当程序运行不是AOK时,会进入异常处理程序</li>
<li>调用一个函数先写的参数会距离栈顶更近,比如一个函数 <code>int sum(int* Start, int Count)</code> 取得传进来的指针Start值用的是 8(%ebp) 取Count值用的是 12(%ebp), 所以,调用的时候, 需要让后面的参数先入栈</li>
<li>完整的汇编代码中,开头会指示这段代码的开始地址,结尾会指示这段代码栈的栈尾地址(栈向低地址增长),整个程序就在两者之间运行,所以要保证栈不要增长的太大覆盖了程序代码</li>
<li><code>pushl %esp</code> 和 <code>popl %esp</code> 的选择

<ul>
<li><code>pushl %esp</code> : push本来就要减少栈指针esp,而push esp又要将栈指针压栈,最后的结果就有两种情况 :

<ol>
<li>压栈的是减少之后的esp</li>
<li>压栈的是原始的esp</li>
</ol>
</li>
<li><code>popl %esp</code> : 同上,有两种情况 :

<ol>
<li>esp中存的是原来的esp指向的值</li>
<li>esp中存的是增减完了的esp指向的值</li>
</ol>
</li>
</ul>


<p>  在Y86中,压入的是原始的esp,弹出的是原始的esp指向的值(具体可以看254页的分段伪代码)</p></li>
<li>存储器和适中:

<ol>
<li>时钟寄存器: 不是%esp这些寄存器,是输入值到输出值由时钟控制的一种硬件</li>
<li>随机访问存储器

<ol>
<li>寄存器文件: 里面包括8个程序寄存器(%eax,%esp),对外提供程序寄存器的读写端口</li>
<li>虚拟存储器系统:也就是内存</li>
</ol>
</li>
</ol>
</li>
</ul>


<h3>顺序实现Y86</h3>

<p>将指令分为六个阶段,每条指令顺序执行,上一条指令执行完最后一个阶段之后才会执行下一个阶段,执行效率低下.</p>

<ul>
<li>取指 : 取指令,根据PC获得icode(指令代码)ifunc(指令功能)寄存器操作码,valC(常数).</li>
<li>译码 : 通过寄存器文件及上一步的寄存器操作码得到相应寄存器的值</li>
<li>执行 : 执行需要的运算(加减,异或,与),并设置条件码</li>
<li>访存 : 访问内存,读或写,比如一些 irmovl , push(栈) 等指令会用到</li>
<li>写回 : 将在访存阶段或者执行阶段得到的值写到存储器里面,用到的硬件和译码相同,都是寄存器文件</li>
<li>更新PC : 根据指令得到下条指令的地址</li>
</ul>


<p>两条指令 : call指令运行会将下一条指令的地址压栈,方便返回
 ret指令用栈顶的值来更新PC,解释了一个函数运行的经过.</p>

<p>整体执行是用时钟控制的,每次时钟由低到高都执行一个阶段.</p>

<p>寄存器文件有两个写的端口,如果想要对同一个寄存器写的话,只有有限制高的端口会执行写操作,这样做也是为了解决上面说的 <code>pushl %esp</code> 的问题,在指令执行过程中,寄存器文件的两个写端口分别分配给
1. 访存得到的 valM
2. 计算得到的 valE
而<code>pushl %esp</code> 指令刚好这两个都要写esp ,所以需要制定优先级,具体的优先级不同的编码实现不同.</p>

<h3>流水线Y86</h3>

<p>书中对流水线的解释很到位</p>

<blockquote><p>&hellip;(顾客点餐)通常都会允许多个顾客同时经过系统,而不是要等到一个用户完成了所有从头到尾的过程才让下一个开始.</p></blockquote>

<p>当某些流水阶段理解晦涩时,可以对比顾客点餐的例子.我是这样理解的: 每个阶段每个时钟都执行不同的指令,比如取值,每个时钟取一条,比如译码,每个时钟译码一条..</p>

<p>使用流水线来处理指令需要流水线寄存器,就是用于每个阶段之间存储的硬件,上面存储的是这个阶段之前,这个阶段需要执行的指令所需的值.
比如访存流水线寄存器(M)里面存储了访存需要的地址,以及上一步运算得到的状态码等等信息.</p>

<p>在276页中的 E寄存器下面可以看到一个叫 <code>Select A</code> 的硬件,它是为了节省存储空间出现的, 在流水线系统中, value A将不止用来存储在寄存器A中得到的值,还用来存储
1. Jxx 不需要跳转时的 valP
2. call 的 valP (需要将本来的下一条指令的地址压栈)
3. irmovl 中本来就需要存的 valA
由于各个指令并不冲突,所以可以共享存储..具体用操作码来区分.</p>

<p>流水线需要解决的一些问题</p>

<h4><strong>流水线冒险</strong></h4>

<p> 两条指令相邻执行,第二条指令执行到译码阶段的时候第一条指令还没执行完,甚至更前面的指令还没执行完,当某条指令的执行需要前面某条指令计算完的值的时候会出现这种问题,有可能会取到错误的值.两种解决方案:
    1. 暂停,暂停当前指令等待前面会影响到后面的值的指令执行完(通过插入bubble)
    2. 转发,后面的指令用到的值可能在前面的指令中已经计算并存储了下来,只是还没放到寄存器里面,这时可以根据不同的情况直接在前面指令的存储设备里面获得需要的值,而不是在寄存器中取(错误的值).</p>

<ul>
<li>转发有一种情况解决不了,就是两条指令相邻,上一条指令要到访存阶段才能得到正确的值,下一条指令在译码阶段就需要该值,这样就结合暂停的方法,暂停第二个指令,等到第一个指令得到了需要的值再继续执行.</li>
<li>另外还有转发的优先级,这个比较容易理解,就是离当前指令越近的指令的指令寄存器优先级越高</li>
</ul>


<h4><strong>异常处理</strong></h4>

<p>当某条指令出现异常的时候,后面的指令有可能会更新程序员可见的状态(状态码),必须禁止,比如当访存或者写回阶段出现异常的时候,需要将执行阶段的信号 <code>set_cc</code> (允许设置状态码)设置为0,就是不允许后续的指令修改状态码.</p>

<h4><strong>ret指令</strong></h4>

<p>遇到ret指令的时候,需要访存结束(得到返回的地址)才能确定下一条指令的地址,在此期间流水线是一直运行的,需要在ret运行后连续3个周期插入bubble,直到可以得到正确的下一个指令的地址(P297)</p>

<h4><strong>预测错误的分支</strong></h4>

<p>对于一些分支跳转的语句,Y86会预测始终选择分支,但是这明显不一定是对的,当分支跳转的指令执行到 执行 阶段的时候就可以验证分支跳转的条件是否成立,如果预测正确就能正确执行,如果预测错误,需要&#8221;取消&#8221;取出来的多余的两条语句,也是通过插入气泡的方式,同时在周期5可以取出正确的下一条语句(P298)</p>

<h4><strong>PC选择</strong></h4>

<p>在流水系统中,PC选择是第一件事,PC有三种选择
1. 刚才提到的分支预测错误情况下, PC选择M_valA中取出预测错误的指令的 valP 当做下一条,因为预测错误,就要执行本来计算好的 valP (下一条指令)了,至于为什么存在 valA里面,前面有说明..
2. 刚才提到的ret指令,需要在 W_valM 中获得下一条
3. 其它情况采用预测值
预测策略刚才也提到了,遇到分支的情况,总是预测会跳转,没有分支直接计算下一条.</p>
]]></content>
  </entry>
  
</feed>
